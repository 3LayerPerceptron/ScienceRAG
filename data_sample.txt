Multiple Imputation of Hierarchical Nonlinear Time Series Data with an
  Application to School Enrollment Data

International comparisons of hierarchical time series data sets based on
survey data, such as annual country-level estimates of school enrollment rates,
can suffer from large amounts of missing data due to differing coverage of
surveys across countries and across times. A popular approach to handling
missing data in these settings is through multiple imputation, which can be
especially effective when there is an auxiliary variable that is strongly
predictive of and has a smaller amount of missing data than the variable of
interest. However, standard methods for multiple imputation of hierarchical
time series data can perform poorly when the auxiliary variable and the
variable of interest have a nonlinear relationship. Performance can also suffer
if the multiple imputations are used to estimate an analysis model that makes
different assumptions about the data compared to the imputation model, leading
to uncongeniality between analysis and imputation models. We propose a Bayesian
method for multiple imputation of hierarchical nonlinear time series data that
uses a sequential decomposition of the joint distribution and incorporates
smoothing splines to account for nonlinear relationships between variables. We
compare the proposed method with existing multiple imputation methods through a
simulation study and an application to secondary school enrollment data. We
find that the proposed method can lead to substantial performance increases for
estimation of parameters in uncongenial analysis models and for prediction of
individual missing values.

#### Abstract

International comparisons of hierarchical time series data sets based on survey data, such as annual country-level estimates of school enrollment rates, can suffer from large amounts of missing data due to differing coverage of surveys across countries and across times. A popular approach to handling missing data in these settings is through multiple imputation, which can be especially effective when there is an auxiliary variable that is strongly predictive of and has a smaller amount of missing data than the variable of interest. However, standard methods for multiple imputation of hierarchical time series data can perform poorly when the auxiliary variable and the variable of interest have a nonlinear relationship. Performance can also suffer if the multiple imputations are used to estimate an analysis model that makes different assumptions about the data compared to the imputation model, leading to uncongeniality between analysis and imputation models. We propose a Bayesian method for multiple imputation of hierarchical nonlinear time series data that uses a sequential decomposition of the joint distribution and incorporates smoothing splines to account for nonlinear relationships between variables. We compare the proposed method with existing multiple imputation methods through a simulation study and an application to secondary school enrollment data. We find that the proposed method can lead to substantial performance increases for estimation of parameters in uncongenial analysis models and for prediction of individual missing values.


1. Introduction. Missing values within hierarchical time series data sets are a common occurrence in social science data, particularly for comparisons across countries and across times that rely on survey data. International surveys may only be conducted in selected years and coverage of countries may differ from year to year, while country-level surveys and censuses may be conducted annually in some countries but may only occur sporadically in others. The presence of missing data can be compounded in settings that require the compilation of data from multiple different sources. One example where this occurs is for school enrollment data, where the UNESCO Institute for Statistics compiles survey and administrative data from countries around the world to create annual, internationally comparable estimates of school enrollment rates. The country-specific time series for school enrollment rates have a hierarchical structure where countries are nested in the world. The differing availability of survey and administrative data across countries and years leads to a large number of country-years in the UNESCO database with missing data.

For hierarchical time series data arising from survey data, there can be multiple variables that measure similar underlying quantities but have differing amounts and patterns of missing data. This is the case for school enrollment data, where two commonly reported measures of school enrollment rates are the Net Enrollment Rate (NER) and the Gross Enrollment Ratio (GER). NER is the ratio of children of official secondary school age who are enrolled in secondary school to the population of official secondary school age children, while GER

Keywords and phrases: Multiple imputation, missing data, Bayesian hierarchical model, time series, school enrollment.

is the ratio of total enrollment in secondary school, regardless of age, to the population of official secondary school age children. NER and GER both aim to measure the same underlying quantity of school enrollment. NER can be thought of as a more refined measure of school enrollment that incorporates information about the age of children who are enrolled in school, while GER is a coarser measure of school enrollment that only requires information about the number of children enrolled. NER is more difficult to measure than GER and has a larger amount of missing data.

More generally, this type of missing data can arise if a survey is designed to collect information on a refined measure of the quantity of interest but includes the option to collect information on a coarse measure of the quantity of interest if the respondent does not provide enough information for the refined measure. For example, a survey on school enrollment might ask for information on the number and ages of children enrolled in school to calculate NER but include the option for respondents to provide only the number of children enrolled to calculate GER. In surveys that do not collect the coarse measure directly, there may exist auxiliary information from external sources, such as administrative records, that can be used as a coarse measure of the quantity of interest. This type of missing data can also occur by design in longitudinal panels to reduce respondent burden. Panel members may be asked to provide basic information for the coarse measure in every cycle of the panel, but may only be asked to provide detailed information for the refined measure in selected cycles. In all of these examples, the refined measure of the quantity of interest tends to have a greater amount of missing data than the coarse measure by nature of being more difficult to measure. If the variable of interest for subsequent analysis is the refined measure, researchers might be interested in how to best leverage information from the coarse measure to impute the variable of interest using a multiple imputation procedure.

Multiple imputation, first developed by Rubin (1978, 1987), is a widely used approach for handling missing data. In multiple imputation, $M>1$ imputed values for missing observations are sampled from the posterior predictive distribution of the missing data given the observed data. The $M$ imputed values result in $M$ completed data sets, each of which consists of the observed data and one set of imputed values for the missing observations. The completed data sets can each be analyzed separately using complete data methods and the results of the analyses can be combined into one final, pooled result using combining rules from Rubin (1987) that account for both within-imputation variation and between-imputation variation. Multiple imputation approaches generally assume data is Missing At Random (MAR) as defined by Rubin (1976). For variable X, MAR occurs when the probability of being missing depends only on the observed portion of $\mathbf{X}$. A special case of MAR occurs when data is Missing Completely At Random (MCAR) and the probability of being missing does not depend on $\mathbf{X}$. Data can also be Missing Not At Random (MNAR), which occurs when the probability of being missing depends on the missing portion of $\mathbf{X}$.

We focus on the setting where the imputation of missing values and the analysis of imputed values are conducted independently. The development of multiple imputation originated in this setting, where Rubin $(1977,1978)$ proposed the multiple imputation framework as a way to provide imputed values for missing responses in public-use releases of large data sets from sample surveys. An appealing feature of multiple imputation for practitioners is the ability to use the same imputed data set to conduct many different analyses (Schafer (1997a); Rubin (1987)). However, using the same multiply imputed data for different analyses can lead to the analysis model being uncongenial to the imputation model in the sense of Meng (1994). An imputation model and an analysis model are congenial if there exists a Bayesian model such that (i) the posterior mean and variance from the Bayesian model for the parameter of interest are asymptotically the same as the mean and variance estimates from the analysis model in both the complete and incomplete data settings and (ii) the posterior predictive distribution of

the missing data given the observed data derived from the Bayesian model is identical to the imputation model (Meng, 1994). When these two conditions are not met, the imputation and analysis models are uncongenial, and theoretical properties of the multiply imputed estimates created using the simple combining rules of Rubin (1987) may not be guaranteed (Meng (1994); Rubin (1996); Xie and Meng (2017)). Rubin's multiply imputed variance estimator is not guaranteed to be asymptotically unbiased for the true repeated sampling variance of the multiply imputed point estimator under uncongeniality, leading to estimated confidence intervals with less than nominal coverage. Uncongeniality of the analysis and imputation models can be a regular occurrence in practice, particularly when the researchers that collect the survey data create imputed values for publication that are then used in analyses by external researchers. The external researchers may not have access to the same information or resources needed to create imputations of their own, for example if the variables used in the imputation model are not publicly available. Specifically, we consider the scenario where imputation of a variable $\mathbf{Y}$ for public release is conducted by leveraging the relationship between $\mathbf{Y}$ and an auxiliary variable $\mathbf{X}$, where $\mathbf{X}$ (and imputed values of $\mathbf{X}$ ) cannot be made publicly available. The multiply imputed values of $\mathbf{Y}$ are subsequently used by an external researcher in an analysis with an external outcome variable, $\mathbf{Z}$, which is unknown to the imputer and is not accounted for in the imputation process. In this scenario, the analysis model used by the external researcher is not guaranteed to be congenial to the imputation model. The ability of a multiple imputation method to perform well for uncongenial analyses is thus of interest for practitioners.

For hierarchical data, multiple imputation approaches that do not explicitly account for the hierarchical structure of the data can lead to biased results in downstream analyses (Taljaard, Donner and Klar (2008); Enders, Mistler and Keller (2016); Lüdtke, Robitzsch and Grund (2017)). Many approaches specifically for multiple imputation of hierarchical time series data have been developed (e.g. Liu, Taylor and Belin (2000); He, Yucel and Raghunathan (2011); Speidel, Drechsler and Jolani (2018); Enders, Du and Keller (2020); Grund, Lüdtke and Robitzsch (2021); among others), with two of the most widely used approaches for social science data being Amelia II and multilevel extensions of Multiple Imputation by Chained Equations (MICE). Amelia, originally developed by King et al. (2001) and extended as Amelia II by Honaker and King (2010), is a multiple imputation method designed specifically for hierarchical time series data. Amelia is based on the joint modeling approach to multiple imputation, where imputed values are sampled from a joint distribution for all variables with missing data. MICE is a multiple imputation method developed by van Buuren and Groothuis-Oudshoorn (2011) that uses the fully conditional specification (FCS) approach to multiple imputation. Rather than explicitly specifying a joint imputation model, the FCS algorithm iteratively samples from univariate conditional imputation models for all variables with missing data until convergence is reached. Several methods that account for hierarchical data structures have been implemented within the MICE framework, including the linear mixed effects method developed by Schafer and Yucel (2002).

The most commonly used methods for multiple imputation of hierarchical time series data assume that the variables in the imputation model have a linear relationship. In settings where variables have a strong nonlinear relationship and transformation to approximate linearity is not possible, these methods are misspecified. Failing to account for the nonlinear relationship can lead to imputed relationships between variables that are implausible based on substantive knowledge and biased estimates in analyses using the multiply imputed data. Nonlinear relationships in hierarchical time series data can occur regularly in the social sciences, for example if rates that aim to measure the same quantity are calculated for related populations. This is the case for school enrollment rates, where NER and GER measure school enrollment for slightly different populations of children. Another example arises for

contraceptive prevalence rates, where country-level estimates of contraceptive prevalence for married and unmarried women have a nonlinear relationship when pooled across countries and times. Measurement of contraceptive use is more difficult for unmarried women than for married women, leading to a larger amount of missing data for unmarried women. A multiple imputation method for hierarchical time series data that can account for this type of nonlinear relationship could be of great utility for such applications. Existing multiple imputation methods that address more general nonlinear settings include methods based on classification and regression trees (Burgette and Reiter (2010)), functional data analysis (He, Yucel and Raghunathan (2011)), B-splines (Mbougua et al. (2013)), and generalized additive models for location, scale, and shape (de Jong, van Buuren and Spiess (2016)). We build upon this existing literature to develop a multiple imputation method for continuous hierarchical time series data that can account for a nonlinear relationship between variables that represent refined and coarse measures of the underlying quantity of interest using smoothing splines. We refer to this method as MINTS for Multiple Imputation of hierarchical Nonlinear Time Series data. We focus on the bivariate setting, where the refined measure is the variable for which imputations are desired, and the coarse measure is an auxiliary variable that is easier to measure and has a nonlinear relationship with the refined measure.

This paper is structured as follows. In Section 2, we describe the motivating case study of secondary school enrollment data in further detail. Section 3 describes the proposed multiple imputation method. In Section 4, we conduct a simulation study to evaluate the out-of-sample validation performance of the proposed multiple imputation method. We compare the performance of the proposed multiple imputation method with several existing multiple imputation methods for estimation of parameters in analysis models that are uncongenial to the imputation model. In Section 5, we conduct two out-of-sample validation exercises using the motivating data set on secondary school enrollment rates, where we evaluate predictive performance for estimation of individual missing values and estimation of parameters in uncongenial analysis models. We also create multiple imputations for the full school enrollment data set and make available 40 multiple imputations for NER created using MINTS. Section 6 includes further discussion and comparisons of the proposed multiple imputation method with existing methods. Finally, we summarize the findings of this paper in Section 7.
2. Motivating Case Study: Secondary School Enrollment Rates. The UNESCO Institute for Statistics collects internationally comparable data on education indicators on an annual basis for all countries of the world, based largely on survey and administrative data (UNESCO Institute for Statistics (2023)). The World Bank combines this education data with population data from the United Nations Population Division to create estimates of two types of enrollment rates: the Net Enrollment Rate (NER) and the Gross Enrollment Ratio (GER) (World Bank (2021)). We focus on secondary school enrollment. NER is the ratio of children of official secondary school age who are enrolled in secondary school to the population of official secondary school age children. NER is bounded between $0 \%$ and $100 \%$ and both the numerator and denominator reflect children of official secondary school age. GER is the ratio of total enrollment in secondary school, regardless of age, to the population of official secondary school age children. The numerator and denominator for GER potentially represent different populations, where children who are not of official secondary school age can be counted in the numerator but not in the denominator. Thus, GER can be greater than $100 \%$ if children who are enrolled in school are not of official school age. The two measures of enrollment have a strong nonlinear relationship and are subject to the boundary NER $\leq$ GER.

For substantive analyses, one measure of enrollment may be preferred over the other. NER can be thought of as a demographic rate, where the numerator counts the number of enrollments for the population of children of official secondary school age in a given year and the

denominator counts the person-years lived in that population for the given year. NER can thus be preferable over GER for demographic analyses. However, historical time series of NER tend to have more missing values than time series of GER, as measurement of NER is more difficult than measurement of GER due to requiring knowledge of the age distribution for children enrolled in school. Measurement of GER is comparatively easy, as GER can be calculated using only the number of children who are currently enrolled. For school systems that do not have robust recordkeeping systems and countries that do not have good vital registration systems, knowledge of the age of all enrolled children can be difficult to obtain. The greater availability of estimates of GER and the strong relationship between NER and GER motivates the desire to impute missing values of NER using the relationship between NER and GER.

We obtain estimates of secondary school enrollment rates for both genders combined from World Bank (2021), ${ }^{1}$ where the definition of secondary school used for each country is based on the International Standard Classification of Education. After excluding all countries and years in the World Bank data base with no observations for either NER or GER, the resulting data set includes 202 countries and 51 years spanning 1970 to 2020 for a total of 10,302 country-year combinations. The overall rate of missingness is about $73.0 \%$ for NER and about $37.6 \%$ for GER. Within countries, the rate of missingness for NER ranges from about $13.7 \%$ missing in Malta to $100 \%$ missing in 14 countries. For GER, the rate of missingness within countries ranges from about $2.0 \%$ missing in Peru to about $98.0 \%$ missing in Curaçao.

Figure 1 shows a scatter plot of the complete cases for NER and GER. The superimposed line illustrates the B-spline of degree 1 fit to the complete cases using the A-splines methodology described in Section 3.2.5. There is a nonlinear relationship between NER and GER, with a shift in trend occurring around GER $=100$. The variation of NER about the fitted spline also appears to vary with GER, with smaller variability at the lowest levels of GER and larger variability around GER $=100$.
![img-0.jpeg](img-0.jpeg)

Fig 1: Scatter plot of complete cases for NER and GER from secondary enrollment data set superimposed with the B-spline of degree 1 fit using A-splines.

[^0]
[^0]:    ${ }^{1}$ Downloaded on August 5, 2021

Time series of NER and GER are shown in Figure 2 for Afghanistan, Belgium, Spain, and Nigeria. Afghanistan is an example of the most common type of pattern seen for individual countries, where there is a larger number of observed values for GER compared to NER. Only one country, Brazil, has the opposite pattern with one more observed value of GER than observed values of NER. Belgium and Spain are two examples of countries where the nonlinear relationship between NER and GER is visible in the time series for the individual country. Both Belgium and Spain have relatively few missing values for GER, but have large stretches of time with no observations for NER. Finally, Nigeria is an example of a country that has some observed values for GER but has no observed values for NER. There are 14 countries in the school enrollment data set that, like Nigeria, have at least one observation for GER but no observations for NER.
![img-1.jpeg](img-1.jpeg)

Fig 2: Observed values of NER and GER for selected countries from secondary enrollment data set. Open and solid circles indicate observed values for NER and GER, respectively.

# 3. Methods. 

3.1. Notation. We consider hierarchical time series data where the clustering variable is country and the time variable is year. Let $X_{c, t}$ denote the auxiliary variable and let $Y_{c, t}$ denote the variable of interest for country $c$ and year $t$, where $c \in 1, \ldots, C$ and $t \in 1, \ldots, T$. The vector of $X_{c, t}$ for all countries at year $t$ is denoted by $\mathbf{X}_{t}=\left[X_{1, t}, X_{2, t}, \ldots, X_{C, t}\right]$. Similarly, the vector of $Y_{c, t}$ for all countries at year $t$ is denoted by $\mathbf{Y}_{t}=\left[Y_{1, t}, Y_{2, t}, \ldots, Y_{C, t}\right]$. The $C$ by $T$ matrix of all $X_{c, t}$ is $\mathbf{X}=\left[\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{T}\right]$ and the $C$ by $T$ matrix of all $Y_{c, t}$ is $\mathbf{Y}=$ $\left[\mathbf{Y}_{1}, \mathbf{Y}_{2}, \ldots, \mathbf{Y}_{T}\right]$.

Let the matrices $\mathbf{R}^{X}$ and $\mathbf{R}^{Y}$ denote the response matrices for $\mathbf{X}$ and $\mathbf{Y}$, respectively. If an element $(c, t)$ is observed, then the corresponding element of the response matrix equals 1 . For example, if $X_{c, t}$ is observed, then $R_{c, t}^{X}=1$. If $X_{c, t}$ is missing, then $R_{c, t}^{X}=0$. The matrices

$\mathbf{X}$ and $\mathbf{Y}$ can also be written in terms of their observed and missing portions. For example, $\mathbf{X}=\left[\mathbf{X}_{\text {mis }}, \mathbf{X}_{\text {obs }}\right]$ where the observed portion of $\mathbf{X}$ is denoted $\mathbf{X}_{\text {obs }}$ and the unobserved portion of $\mathbf{X}$ is denoted $\mathbf{X}_{\text {mis }}$.

For the school enrollment data, the auxiliary variable $\mathbf{X}$ is GER and the variable of interest $\mathbf{Y}$ is NER. The enrollment data includes a total of $C=202$ countries, where the assignment of countries to indices $c \in 1, \ldots, C$ was done alphabetically by country name. There are $T=$ 51 years in the enrollment data set, where $t=1$ corresponds to the year 1970 and $t=51$ corresponds to the year 2020 .

# 3.2. Model. 

3.2.1. Assumptions. We assume the missing data mechanism is ignorable, i.e., the missing data mechanism is Missing At Random (MAR, defined in Section 4.3) and the parameters of the complete data model for $(\mathbf{X}, \mathbf{Y})$ are distinct and a priori independent from the parameters of the missing data model governing the response matrices $\mathbf{R}^{X}$ and $\mathbf{R}^{Y}$ (Rubin (1976); Schafer (1997a); Little and Rubin (2002)). The assumption of ignorability allows for imputation without specification of a model for the missing data mechanism. Using $\mathbf{X}$ as an example, imputed values are said to be Bayesianly proper in the sense of Schafer (1997a) if they are independently drawn from the posterior distribution $p\left(\mathbf{X}_{\text {mis }} \mid \mathbf{X}_{\text {obs }}, \mathbf{R}^{X}\right)$. When the missing data mechanism is ignorable, proper imputations can instead be drawn from the posterior distribution $p\left(\mathbf{X}_{\text {mis }} \mid \mathbf{X}_{\text {obs }}\right)=\int p\left(\mathbf{X}_{\text {mis }} \mid \mathbf{X}_{\text {obs }}, \theta\right) p\left(\theta \mid \mathbf{X}_{\text {obs }}\right) d \theta$ where $\theta$ is the vector of parameters for the complete data. The assumption of ignorability is ubiquitous for generalpurpose imputation models, but in practice researchers cannot know if this assumption is met. We conducted sensitivity analyses in Sections 4 and 5 to evaluate how well the MINTS method performs when the ignorability assumption is violated.

Finally, we assume that the auxiliary variable is observed at least once for each country for which we are interested in imputing the variable of interest. That is, both $\mathbf{X}$ and $\mathbf{Y}$ can contain missing values for any country-year, but we assume that each country has at least one year in which $X_{c, t}$ is observed. This reflects the motivating setting for the proposed imputation method, where the auxiliary variable is more likely to be observed in each country than the variable of interest due to being easier to measure.
3.2.2. Sequential Decomposition of Joint Model. The MINTS method uses a variation of the joint modeling approach to multiple imputation. In the usual joint modeling approach, the complete data $(\mathbf{X}, \mathbf{Y})$ is assumed to follow a multivariate joint distribution and imputed values are sampled from the joint posterior predictive distribution of the missing data given the observed data. One downside to this approach is the difficulty of specifying a joint distribution for all variables used in the imputation model. A common general-purpose choice for the joint distribution is the multivariate normal distribution, which has been found to still perform reasonably well for imputation even when the assumption of normality is violated (Schafer (1997a); Schafer and Olsen (1998)). However, if there are nonlinear relationships between variables in the imputation model, joint modeling assuming multivariate normality is unable to incorporate those relationships.

A more flexible approach to multiple imputation is the fully conditional specification (FCS) approach, also known as imputation via chained equations (van Buuren et al. (2006)) and sequential regression multivariate imputation (Raghunathan et al. (2001)), among other names. FCS does not explicitly specify a joint distribution for the variables with missing data. Instead, univariate conditional distributions are specified for each variable with missing data given all other variables in the imputation model. Missing values are imputed by iteratively sampling from the univariate conditional distributions until convergence for all imputation

model parameters is reached. The conditional distributions can take any form and can accommodate nonlinear relationships between variables. However, this level of flexibility can lead to cases where the univariate conditional distributions are not compatible. Although simulation studies show that FCS can result in reasonable imputations even when the conditional distributions are not compatible (e.g. van Buuren et al. (2006)), ultimately FCS does not guarantee that the iterative conditional algorithm will converge to a proper joint distribution (Li, Yu and Rubin (2012)).

We use an alternative to the usual joint modeling approach that combines desirable features of joint modeling and FCS through a sequential decomposition of the joint model. The sequential decomposition approach for joint modeling was first proposed by Lipsitz and Ibrahim (1996) and has been extended by Ibrahim, Lipsitz and Chen (1999); Ibrahim, Chen and Lipsitz (2002); Lee and Mitra (2016); Xu, Daniels and Winterstein (2016); Lüdtke, Robitzsch and West (2020); among others. The joint distribution of the variables with missing data is decomposed into a sequence of univariate conditional distributions. One possible decomposition of the joint distribution for $(\mathbf{X}, \mathbf{Y})$ is

$$
p(\mathbf{X}, \mathbf{Y} \mid \boldsymbol{\theta})=p\left(\mathbf{Y} \mid \mathbf{X}, \boldsymbol{\theta}_{Y}\right) p\left(\mathbf{X} \mid \boldsymbol{\theta}_{X}\right)
$$

The vector of parameters for the joint distribution is $\boldsymbol{\theta}$, the vector of parameters for the conditional distribution of $\mathbf{Y} \mid \mathbf{X}$ is $\boldsymbol{\theta}_{Y}$, and the vector of parameters for the distribution of $\mathbf{X}$ is $\boldsymbol{\theta}_{X}$. Unlike in FCS, this sequence of univariate conditional distributions is guaranteed to correspond to a well-defined joint distribution by construction.

The sequential decomposition approach allows for greater flexibility compared to joint modeling, but is not quite as flexible as FCS due to the additional restriction of requiring an ordering for the conditional distributions. The choice of ordering can have a substantial impact on the performance of the imputation model due to the risk of conditional distributions being incorrectly specified. We follow standard guidelines proposed by Rubin and Schafer (1990) and choose the ordering based on the percentage of missing values. For the ordering in Equation 1, the variable of interest $\mathbf{Y}$ has a larger amount of missing data compared to the auxiliary variable $\mathbf{X}$.
3.2.3. Model Specification. The joint distribution of $(\mathbf{Y}, \mathbf{X})$ is decomposed sequentially following Equation 1 as the product of the distribution of $\mathbf{Y} \mid \mathbf{X}$ and the distribution of $\mathbf{X}$. The distribution of $\mathbf{X}$ is further decomposed as

$$
p\left(\mathbf{X} \mid \boldsymbol{\theta}_{X}\right)=\left(\prod_{t=1}^{T} p\left(\mathbf{X}_{t} \mid \mathbf{X}_{t-1}, \boldsymbol{\theta}_{X}\right)\right) p\left(\mathbf{X}_{0} \mid \boldsymbol{\theta}_{X}\right)
$$

where $\mathbf{X}_{0}$ is a parameter that represents the vector of $X_{c, 0}$ for all countries $c$ at the unobserved year $t=0$. Similarly, the conditional distribution of $\mathbf{Y} \mid \mathbf{X}$ is further decomposed as

$$
p\left(\mathbf{Y} \mid \mathbf{X}, \boldsymbol{\theta}_{Y}\right)=\left(\prod_{t=1}^{T} p\left(\mathbf{Y}_{t} \mid \mathbf{Y}_{t-1}, \mathbf{X}_{t}, \boldsymbol{\theta}_{Y}\right)\right) p\left(\mathbf{Y}_{0} \mid \mathbf{X}_{0}, \boldsymbol{\theta}_{Y}\right)
$$

where $\mathbf{Y}_{0}$ is a parameter that represents the vector of $Y_{c, 0}$ for all countries $c$ at the unobserved year $t=0$.

The distribution of $\mathbf{X}_{t} \mid \mathbf{X}_{t-1}, \boldsymbol{\theta}_{X}$ is modeled as a random walk with a country-specific drift term $\gamma_{c}$. For country $c$ and $t \in 1, \ldots, T$,

$$
\begin{aligned}
X_{c, t} \mid X_{c, t-1}, \boldsymbol{\theta}_{X} & \sim T N_{\left[X_{\text {low }}, X_{u p}\right]}\left(X_{c, t-1}+\gamma_{c}, \sigma_{X}^{2}\right) \\
\gamma_{c} & \sim N\left(\mu_{\text {drift }}, \sigma_{\text {drift }}^{2}\right)
\end{aligned}
$$

where $T N_{\left[\mathrm{X}_{\text {low }}, \mathrm{X}_{\text {up }}\right]}$ refers to the truncated normal distribution with lower bound $X_{\text {low }}$ and upper bound $X_{u p}$. These boundaries should be specified based on substantive knowledge about the range of $\mathbf{X}$ and can vary with $(c, t)$, but the dependency is suppressed in the notation. The country-specific drift terms $\gamma_{c}$ follow a world-level distribution where $\mu_{\text {drift }}$ and $\sigma_{d r i f t}^{2}$ are world-level hyperparameters.

The conditional distribution of $\mathbf{Y}_{t} \mid \mathbf{Y}_{t-1}, \mathbf{X}_{t}, \boldsymbol{\theta}_{Y}$ is modeled with a country-specific intercept $\alpha_{c}$, a nonlinear function $f$ of $\mathbf{X}$ with coefficient $\beta$, and an $\operatorname{AR}(1)$ term with autoregressive parameter $\rho$. The variance model for $\mathbf{Y}_{t} \mid \mathbf{Y}_{t-1}, \mathbf{X}_{t}, \boldsymbol{\theta}_{Y}$ models heteroscedasticity as a function $h$ of $\mathbf{X}$. For country $c$ and $t \in 1, \ldots, T$,

$$
\begin{aligned}
Y_{c, t} \mid Y_{c, t-1}, X_{c, t}, \boldsymbol{\theta}_{Y} & \sim T N_{\left[Y_{l o w}, Y_{u p}\right]}\left(\alpha_{c}+\beta f\left(X_{c, t}\right)+\rho Y_{c, t-1}, \sigma_{Y}^{2} h\left(X_{c, t}\right)\right) \\
\alpha_{c} & \sim N\left(\mu_{0}, \sigma_{0}^{2}\right)
\end{aligned}
$$

where $T N_{\left[Y_{l o w}, Y_{u p}\right]}$ refers to the truncated normal distribution with lower bound $Y_{\text {low }}$ and upper bound $Y_{u p}$. These boundaries should be specified based on substantive knowledge about the range of $\mathbf{Y}$ and can vary with $(c, t)$, but the dependency is suppressed in the notation. The country-specific intercepts $\alpha_{c}$ follow a world-level distribution where $\mu_{0}$ and $\sigma_{0}^{2}$ are world-level hyperparameters.

# 3.2.4. Prior Distributions. The prior distributions are specified as 

$$
\begin{aligned}
\sigma_{X}^{2} & \sim \operatorname{InvGamma}\left(2, \delta_{X}\right) \\
\mu_{\text {drift }} & \sim N\left(\nu_{\text {drift }}, \zeta_{\text {drift }}^{2}\right) \\
\sigma_{\text {drift } 2} & \sim \operatorname{InvGamma}\left(2, \delta_{\text {drift }}\right) \\
\sigma_{Y}^{2} & \sim \operatorname{InvGamma}\left(2, \delta_{Y}\right) \\
\mu_{0} & \sim N\left(0, \zeta_{0}^{2}\right) \\
\sigma_{0}^{2} & \sim \operatorname{InvGamma}\left(2, \delta_{0}\right) \\
\beta & \sim N(0,1) \\
\rho & \sim U(0,1)
\end{aligned}
$$

where the hyperparameters $\delta_{X}, \nu_{\text {drift }}, \zeta_{\text {drift }}, \delta_{\text {drift }}, \delta_{Y}, \zeta_{0}$, and $\delta_{0}$ are control parameters that are used to adjust the prior distributions to the appropriate scale for the data.

For all $c$, the joint prior distribution of $\left(Y_{c, 0}, X_{c, 0}\right)$ is a truncated normal distribution with control parameters $\boldsymbol{\mu}_{\text {early }}$ and $\boldsymbol{\Sigma}_{\text {early }}$ given by

$$
\left[\begin{array}{l}
Y_{c, 0} \\
X_{c, 0}
\end{array}\right] \sim T N\left(\boldsymbol{\mu}_{\text {early }}, \boldsymbol{\Sigma}_{\text {early }}\right)
$$

The truncation is such that $X_{c, 0} \in\left[X_{0, \text { low }}, X_{0, u p}\right]$ and $Y_{c, 0} \in\left[Y_{0, \text { low }}, Y_{0, u p}\right]$. These boundaries should be specified based on substantive knowledge about the ranges of $\mathbf{X}$ and $\mathbf{Y}$ and can vary with $c$, but this dependency is suppressed in the notation. The control parameters $\boldsymbol{\mu}_{\text {early }}$ and $\boldsymbol{\Sigma}_{\text {early }}$ are shared across all $c$.

Priors were chosen to be conjugate and diffuse for most parameters. An informative prior was used for the autoregressive parameter $\rho$ in the imputation model for $\mathbf{Y} \mid \mathbf{X}$ to reflect the prior belief that $\mathbf{Y}$ is generally increasing over time for the motivating school enrollment data, but should generally be specified based on the data being imputed. As the spline term $\beta f\left(X_{c, t}\right)$ and the $\operatorname{AR}(1)$ term $\rho Y_{c, t-1}$ are both on the scale of $Y_{c, t}$, the parameters $\beta$ and $\rho$ can be interpreted as weights that represent the relative importance of the spline term and the

$\operatorname{AR}(1)$ term. The prior distribution for $\beta$ was chosen to be on the same order of magnitude as $\rho$ to reflect this interpretation.

The values for all hyperparameters should ideally be determined using prior expert knowledge. In the absence of sufficient expertise to specify the prior distributions directly, researchers creating multiple imputations are still likely to have non-expert knowledge of the substantive application that can be used to determine the appropriate order of magnitude for the parameters. Using the school enrollment data as an example, researchers may not have the expertise to specify the prior distributions for $\mu_{\text {drift }}$ and $\sigma_{\text {drift }}^{2}$ directly. However, they may still have vague prior knowledge that the country-specific drift terms for GER should generally be positive and that increases in school enrollment happen slowly over time for most countries.

As an approximate quantification of this type of vague prior knowledge, we propose an algorithm for specifying diffuse priors dictated by data-based control parameters in the absence of prior expert knowledge. The data-based algorithm enables semi-automated specification of prior distributions using sample statistics calculated from the observed data. The control parameters for the prior distributions of the $\mathbf{X}$ model $\left(\delta_{X}, \nu_{\text {drift }}, \zeta_{\text {drift }}\right.$, and $\delta_{\text {drift }}$ ) are estimated using summary statistics for the observed first differences $X_{c, t}-X_{c, t-1}$ in $\mathbf{X}_{\text {obs }}$. Similarly, the control parameters for the prior distributions of the $\mathbf{Y} \mid \mathbf{X}$ model $\left(\delta_{Y}, \zeta_{0}\right.$, and $\left.\delta_{0}\right)$ are estimated using summary statistics for the observed first differences $Y_{c, t}-Y_{c, t-1}$ in $\mathbf{Y}_{\text {obs }}$. The control parameters $\boldsymbol{\mu}_{\text {early }}$ and $\boldsymbol{\Sigma}_{\text {early }}$ for the prior distributions of $\left(Y_{c, 0}, X_{c, 0}\right)$ are estimated using summary statistics for $\mathbf{Y}$ and $\mathbf{X}$ from a subset of the data that corresponds to "early" values of $t$, where the range of $t$ that is considered "early" is determined using substantive knowledge of the application. Further details of the algorithm can be found in Section 1 of the Supplementary Material (Liu and Raftery (2025)), and an example illustrating how the algorithm is used to specify prior distributions for the school enrollment data can be found in Section 5.4. We note that use of a data-based algorithm to specify prior distributions results in an approximate posterior distribution rather than a fully Bayesian posterior distribution (Darnieder, 2011).

Although the proposed data-based algorithm is designed to specify prior distributions that are sufficiently diffuse such that the control parameters do not overwhelm the posterior inference following the philosophy of Edwards, Lindman and Savage (1963), the prior distributions resulting from the algorithm should not be used blindly. The prior distributions should be checked to ensure they are sensible for the substantive application and do not unnecessarily restrict the parameter space. For the specification of $\boldsymbol{\mu}_{\text {early }}$ and $\boldsymbol{\Sigma}_{\text {early }}$, the data-based algorithm assumes that the time series for $\mathbf{X}$ and $\mathbf{Y}$ change smoothly over time and that the unobserved values $\left(Y_{c, 0}, X_{c, 0}\right)$ are similar to the observed values in the early subset of data. If there is reason to believe these assumptions are violated, the data-based algorithm should be used with caution.
3.2.5. A-splines. The nonlinear functions $f$ and $h$ in Equation 3 are estimated through spline regression using the complete cases in $(\mathbf{X}, \mathbf{Y})$. To estimate $f$, the model $Y_{c, t}=$ $f\left(X_{c, t}\right)+\varepsilon_{c, t}^{f}$ is fit with Gaussian errors using a B-spline of degree 1. The residuals from the estimation of $f$ are then used to estimate $h$ by fitting the model $\left|Y_{c, t}-f\left(X_{c, t}\right)\right|=$ $h\left(X_{c, t}\right)+\varepsilon_{c, t}^{h}$ with Gaussian errors and using a B-spline of degree 1. After estimation, $f$ is truncated to have range $\left[Y_{\text {low }}, Y_{\text {up }}\right]$ and $h$ is truncated to have range $[\epsilon, \infty)$, where $\epsilon$ is a small positive value. The number and placement of knots for the B-splines used for $f$ and $h$ are selected using a method called adaptive splines, or A-splines (Goepp, Bouaziz and Nuel (2018)). A-splines automates the selection of knots using an iterative penalized likelihood approach and is implemented in the R package "aspline" (Goepp (2022)).

# 3.3. Estimation. 

3.3.1. Model Estimation. The MINTS model is estimated using a Markov chain Monte Carlo (MCMC) algorithm with Gibbs sampling and Metropolis-Hastings steps in R. Multiple imputations are created in two phases. The parameters of the imputation model are first estimated in the estimation phase. In the imputation phase, additional iterations from the same MCMC algorithm are run and used to create multiply imputed data sets.

Estimation of the imputation model parameters occurs simultaneously with estimation of the missing values in a similar fashion to the data augmentation algorithm of Tanner and Wong (1987), with the MCMC algorithm resulting in samples from the joint posterior distribution of the imputation model parameters and the missing values given the observed data. At each iteration of the MCMC algorithm, two steps are iterated until convergence is reached. First, values of the imputation model parameters are drawn from their posterior distributions given the observed data and the most recent estimates of the missing values. Second, estimates for the missing values are drawn from their posterior distributions given the observed data and the previously drawn imputation model parameters.

The nonlinear functions $f$ and $h$ are estimated before the start of the MCMC algorithm using the complete cases in the data, pooled across countries and times. The same estimates of $f$ and $h$ are used throughout the estimation and imputation phases. $f$ and $h$ are treated as deterministic within the MCMC algorithm, and uncertainty in the estimation of the nonlinear functions is not accounted for.

Let $\boldsymbol{\theta}_{X}=\left(\boldsymbol{\gamma}, \sigma_{X}^{2}, \mathbf{X}_{0}, \mu_{\text {drift }}, \sigma_{\text {drift }}^{2}\right)$ and $\boldsymbol{\theta}_{Y}=\left(\boldsymbol{\alpha}, \beta, \rho, \sigma_{Y}^{2}, \mathbf{Y}_{0}, \mu_{0}, \sigma_{0}^{2}\right)$ denote the parameters of the models for $\mathbf{X}$ and $\mathbf{Y} \mid \mathbf{X}$, respectively. The general approach of the MCMC algorithm proceeds as follows for iterations $i=1, \ldots, n_{\text {iter }}$ :

1. Draw $\boldsymbol{\theta}_{X}^{(i)}$ from $p\left(\boldsymbol{\theta}_{X} \mid \mathbf{X}_{\text {obs }}, \mathbf{X}_{\text {mis }}^{(i-1)}\right)$
2. Let $j=1, \ldots, J$ index the $X_{c, t}$ in $\mathbf{X}_{\text {mis }}$. For each $j$, draw $X_{j}^{(i)}$ from

$$
p\left(X_{j} \mid \mathbf{X}_{o b s}, X_{1}^{(i)}, X_{2}^{(i)}, \ldots, X_{j-1}^{(i)}, X_{j+1}^{(i-1)}, \ldots, X_{J}^{(i-1)}, \boldsymbol{\theta}_{X}^{(i)}\right)
$$

3. Draw $\boldsymbol{\theta}_{Y}^{(i)}$ from $p\left(\boldsymbol{\theta}_{Y} \mid \mathbf{Y}_{\text {obs }}, \mathbf{Y}_{\text {mis }}^{(i-1)}, \mathbf{X}_{\text {obs }}, \mathbf{X}_{\text {mis }}^{(i)}\right)$
4. Let $k=1, \ldots, K$ index the $Y_{c, t}$ in $\mathbf{Y}_{\text {mis }}$. For each $k$, draw $Y_{k}^{(i)}$ from

$$
p\left(Y_{k} \mid \mathbf{Y}_{o b s}, Y_{1}^{(i)}, Y_{2}^{(i)}, \ldots, Y_{k-1}^{(i)}, Y_{k+1}^{(i-1)}, \ldots, Y_{K}^{(i-1)}, \mathbf{X}_{o b s}, \mathbf{X}_{m i s}^{(i)}, \boldsymbol{\theta}_{Y}^{(i)}\right)
$$

The total number of iterations $n_{\text {iter }}$ used in the estimation phase is determined based on convergence diagnostics such as inspection of trace plots and evaluation of the diagnostics of Raftery and Lewis (1996) and Gelman and Rubin (1992). Complete details of the MCMC algorithm can be found in Section 2 of the Supplementary Material (Liu and Raftery (2025)).
3.3.2. Imputation Procedure. After the MCMC algorithm has converged for estimation of the imputation model parameters, the imputation phase begins. All iterations of the MCMC that were required for convergence are treated as burn-in during the imputation phase. Imputed values for $\mathbf{X}_{\text {mis }}$ and $\mathbf{Y}_{\text {mis }}$ are created by continuing the MCMC algorithm with additional thinning steps. Thinning of the MCMC chains is required during the imputation phase to ensure that the imputed data sets are approximately independent draws from the posterior predictive distribution of the missing data given the observed data under the model described in Section 3.2.3 and priors described in Section 3.2.4. The amount of thinning is chosen so that the autocorrelation of the imputed values is approximately zero.

The number of iterations used in the imputation phase depends on the desired number of multiply imputed data sets, the number of chains of the MCMC, and the number of iterations

used for thinning. To obtain $M$ multiply imputed data sets from $C$ chains with $n_{\text {thin }}$ iterations between imputed values, the MCMC algorithm is run for an additional $\frac{M}{C} \times n_{\text {thin }}$ iterations for each chain.

We note that although missing data is imputed for both $\mathbf{X}_{\text {mis }}$ and $\mathbf{Y}_{\text {mis }}$, the goal of MINTS is to create multiple imputations of $\mathbf{Y}$. The auxiliary variable $\mathbf{X}$ is imputed out of necessity since $\mathbf{X}$ can also have missing data, but the imputed values of $\mathbf{X}$ are not intended to be used in subsequent analyses.
4. Simulation Study. We conducted a simulation study to evaluate how well the MINTS method performs for estimation of analysis models that are uncongenial to the imputation model, where uncongeniality arises because imputation of missing data and analysis of imputed data are conducted independently and information is not shared between imputation and analysis tasks. We refer to this validation exercise as "analysis model validation."

Analysis model validation was conducted for a simulated data set where a nonlinear relationship was simulated between variables. We considered nine experiments corresponding to three rates of simulated missingness and three missing data mechanisms. Each experiment was replicated $N_{\text {rep }}=1000$ times. The average performance across replications for MINTS was compared with the performance of existing multiple imputation methods for hierarchical time series data. Details of the simulation study using the nonlinear simulated data are presented in this section, while details of an analogous simulation study using linear simulated data are available in Sections 5 and 6 of the Supplementary Material (Liu and Raftery (2025)).
4.1. Data Generation. Variables $\mathbf{X}$ and $\mathbf{Y}$ were generated for 20 countries and 30 years for a total sample size of 600 country-years. $\mathbf{Y}$ is the variable of interest for substantive analyses, while $\mathbf{X}$ is an auxiliary variable that is only of interest for imputation of $\mathbf{Y}$.
$\mathbf{X}$ was simulated independently for each country and is bounded in $[0,100]$. For country $c$,

$$
\begin{aligned}
X_{c, 1} & \left.\sim U\left(X_{1, l o w}, X_{1, u p}\right)\right. \\
X_{c, t+1} & \left.\sim T N_{[0,100]}\left(X_{c, t}+\gamma_{c}, \sigma^{2}\right) \text { for } t=1, \ldots, 29\right)
\end{aligned}
$$

where $T N_{[0,100]}$ refers to the truncated normal distribution with support $[0,100]$ and $\gamma_{c}$ is a country-specific drift term. For the nonlinear simulated data, we set $X_{1, l o w}=0, X_{1, u p}=25$, $\sigma^{2}=1$, and $\gamma_{c} \sim U(1,3)$.
$\mathbf{Y}$ was simulated to have a nonlinear relationship with $\mathbf{X}$ and is bounded as $Y_{c, t} \in$ $\left[0, \min \left(X_{c, t}, 60\right)\right]$. For country $c$,

$$
\begin{aligned}
Y_{c, t} & \left.\sim T N_{\left[0, \min \left(X_{c, t}, 60\right)\right]}\left(\alpha_{c}+\frac{40}{\left(1+\exp \left(-\frac{X_{c, t}-60}{8}\right)\right)}+3 \log \left(X_{c, t}\right), 1^{2}\right) \\
\alpha_{c} & \left.\sim U(0,5)\right)
\end{aligned}
$$

where $T N_{\left[0, \min \left(X_{c, t}, 60\right)\right]}$ refers to the truncated normal distribution with support $\left[0, \min \left(X_{c, t}, 60\right)\right]$. $\mathbf{X}$ and $\mathbf{Y}$ were constructed to have a generally monotonically increasing relationship similar to the relationship observed for the enrollment data. We assume that the bounds of $\mathbf{X}$ and $\mathbf{Y}$ are known to the imputer.
4.2. Analysis Model. We focused on the setting where the analysis model is uncongenial to the imputation model. The variable $\mathbf{Z}$ is treated as the outcome variable and was simulated

to have a linear relationship with $\mathbf{Y}$. For each country $c$ and year $t$,

$$
\begin{aligned}
Z_{c, t} & \sim N\left(\eta_{c}+2 Y_{c, t}, 10^{2}\right) \\
\eta_{c} & \sim U(0,15)
\end{aligned}
$$

The analysis model is the linear regression of $\mathbf{Z}$ on $\mathbf{Y}$. The parameter of interest is $\omega_{1}$, the coefficient on $\mathbf{Y}$ in the regression

$$
\begin{aligned}
Z_{c, t} & =\omega_{0}+\omega_{1} Y_{c, t}+\varepsilon_{c, t}^{\omega} \\
\varepsilon_{c, t}^{\omega} & \sim N\left(0, \sigma_{\varepsilon_{\omega}}^{2}\right)
\end{aligned}
$$

This analysis model is uncongenial to the imputation model due to the presence of $\mathbf{Z}$, which is not included in any of the imputation models considered. We assume $\mathbf{X}$ is only available during the imputation task and is not possible to include in subsequent analyses. For example, this could occur if the refined measure $\mathbf{Y}$ comes from survey data and the coarse measure $\mathbf{X}$ comes from confidential administrative records data. Multiply imputed values of $\mathbf{Y}$ are desired for public release, but $\mathbf{X}$ cannot be made publicly available. We also assume $\mathbf{Z}$ is only available during the analysis task and is not possible to include in the imputation model. This could occur if $\mathbf{Z}$ is collected by the analyst after the multiple imputation task is complete or because $\mathbf{Z}$ is unavailable to the imputer for data confidentiality reasons. We note that omitted variable bias is likely to occur in this setting due to the omission of $\mathbf{Z}$ in the imputation model, so a data augmentation approach based on MINTS that incorporates $\mathbf{Z}$ into the imputation model is also considered in the validation exercises for comparison purposes.

Additional validation results for a random intercept analysis model can be found in Section 4 of the Supplementary Material (Liu and Raftery (2025)).
4.3. Analysis Model Validation Procedure. Data was simulated as missing following the three missing data mechanisms of Rubin (1976): Missing Completely At Random (MCAR), Missing At Random (MAR), and Missing Not at Random (MNAR). For a variable X, MCAR occurs when $P\left(\mathbf{R}^{X} \mid \mathbf{X}\right)=P\left(\mathbf{R}^{X}\right)$. Data was simulated as missing under MCAR by assuming that each observation has the same probability of being missing. MAR occurs when $P\left(\mathbf{R}^{X} \mid \mathbf{X}\right)=P\left(\mathbf{R}^{X} \mid \mathbf{X}_{\text {obs }}\right)$. Data was simulated as missing under MAR by assuming that observations in earlier years are more likely to be missing. Finally, MNAR occurs when the probability of being missing depends on both the missing and the observed data and $P\left(\mathbf{R}^{X} \mid \mathbf{X}\right)$ cannot be simplified further. Data was simulated as missing under MNAR by assuming that the probability of $\mathbf{X}$ being missing depends on the value of $\mathbf{X}$. Details of the MAR and MNAR implementations can be found in Section 3 of the Supplementary Material (Liu and Raftery (2025)).

For each missing data mechanism, data was simulated as missing at the $10 \%, 40 \%$, and $80 \%$ rates. Each combination of missing data mechanism and rate was implemented simultaneously for $\mathbf{X}$ and $\mathbf{Y}$ and defines an experiment. For example, the MCAR $10 \%$ experiment corresponds to the setting where $10 \%$ of $\mathbf{X}$ was simulated as missing under MCAR and $10 \%$ of $\mathbf{Y}$ was simulated as missing under MCAR. We note that while $80 \%$ is a high rate of missingness, it is similar to the observed rate of $73.0 \%$ missingness for NER in the school enrollment data set.

All multiple imputation methods compared in the validation exercises assume that the missing data mechanism is MAR and that there is sufficient information from the observed data to adequately estimate the relationship between $\mathbf{X}$ and $\mathbf{Y}$. The experiments where data is simulated under MNAR act as a sensitivity analysis to evaluate each method's performance when the MAR assumption is violated. Similarly, the experiments using the $80 \%$ rate of

simulated missingness are considered to assess how well each method performs when there is a very large amount of missing data. In practice, substantive knowledge about the variables with missing data should be used to determine if multiple imputation is appropriate for use if the missing data mechanism is suspected to be MNAR or if there are large amounts of missing data.

For each experiment, the analysis model validation procedure is

1. For replication $r=1, \ldots, N_{\text {rep }}$,
a) Simulate missing values according to the experiment's missing data mechanism and rate to separate the data into "observed" and "missing" data
b) Run the multiple imputation procedure using the observed data to create $M=40$ completed data sets. Completed data sets consist of the observed data and the imputed values for the missing data.
c) Estimate quantities of interest $Q$ using each of the $M$ completed data sets
d) Pool the estimates of $Q$ and $S E(Q)$ across the $M$ completed data sets using combining rules from Rubin (1987) to obtain the pooled estimates $\bar{Q}_{r}$ and $S E\left(\bar{Q}_{r}\right)$
2. Calculate the true value of $Q$ using the full data set
3. Calculate evaluation metrics for the pooled estimates $\bar{Q}_{r}$ averaged across replications

The number of imputations $M=40$ was chosen to balance between having a large enough number of imputations to guarantee minimal contribution of simulation error to the variability of estimands and having a small enough number of imputations to be computationally feasible.

Pooled estimates for each scalar quantity of interest $Q$ are created using combining rules from Rubin (1987) in Step 1(d) of the validation procedure. Let $\bar{Q}_{m}$ denote the point estimate of $Q$ from imputation $m$ and let $\bar{U}_{m}$ denote its associated variance. The pooled point estimate of $Q$ across all $M$ imputations is $\bar{Q}_{M}=\frac{1}{M} \sum_{m=1}^{M} \bar{Q}_{m}$. The pooled variance estimate of $\bar{Q}_{M}$ is $T_{M}=\bar{U}_{M}+\left(1+\frac{1}{M}\right) B_{M}$, where $\bar{U}_{M}=\frac{1}{M} \sum_{m=1}^{M} \bar{U}_{m}$ is the average within-imputation variance and $B_{M}=\frac{1}{M-1} \sum_{m=1}^{M}\left(\bar{Q}_{m}-\bar{Q}_{M}\right)^{T}\left(\bar{Q}_{m}-\bar{Q}_{M}\right)$ is the betweenimputation variance. The $95 \%$ confidence interval for the pooled estimate $\bar{Q}_{M}$ is constructed using $\bar{Q}_{M} \pm t_{\nu}^{*} \sqrt{T_{M}}$, where $t_{\nu}^{*}$ is the critical value for $95 \%$ confidence from the $t$ distribution with $\nu$ degrees of freedom. The degrees of freedom $\nu$ for finite number of imputations $M$ is $\nu=(M-1)\left(1+\frac{1}{r_{M}}\right)^{2}$, where $r_{M}$ is the relative increase in variance due to nonresponse given by $r_{M}=\left(1+\frac{1}{M}\right) \frac{B_{M}}{\bar{U}_{M}}$.

The performance of the point estimates $\bar{Q}_{M}$ was evaluated using the mean absolute error (MAE), calculated as $\frac{1}{N_{\text {rep }}} \sum_{r}\left|\bar{Q}_{M}-Q\right|$ where the sum is taken over all replications within each experiment. The performance of the $95 \%$ confidence intervals for the pooled estimates $\bar{Q}_{M}$ was evaluated using the mean coverage across all replications within each experiment, calculated as the proportion of intervals that contained the true value. We also evaluated the mean fraction of Fisher information about $Q$ that is missing due to nonresponse, which we abbreviate as FMI for Fraction of Missing Information. In each replication of each experiment, FMI is estimated as

$$
\text { FMI }=\frac{r_{M}+\frac{2}{\nu+3}}{r_{M}+1}
$$

The mean FMI across all replications within each experiment enables assessment of the amount of information about $Q$ that is lost due to the presence of missing data (Schafer (1997a); Savalei and Rhemtulla (2012)). We note that with $M=40$ imputations, the estimates of FMI may be noisy, so in this case FMI should only be interpreted as an exploratory diagnostic (Bodner (2008); Enders (2010)).

4.4. Model Implementation. For each replication of each experiment, we created 40 imputations using the MINTS method by running 10 chains of the MCMC algorithm. The bounds of the model for $\mathbf{X}$ were set as $X_{\text {low }}=0$ and $X_{u p}=100$, and the bounds of the model for $\mathbf{Y} \mid \mathbf{X}$ were set as $Y_{\text {low }}=0$ and $Y_{u p}=\min \left(X_{c, t}, 60\right)$. During the estimation phase, the MCMC algorithm was run for enough iterations to ensure convergence of all imputation model parameters. The number of iterations differed across experiments, but ranged from 10,000 to 25,000 iterations per chain. During the imputation phase, an additional 4,000 iterations was run for each chain and four iterations from each chain were selected as the imputed values. The iterations selected as the final imputed values were chosen to be 1,000 iterations apart to ensure autocorrelation was close to zero following the procedure described in Section 3.3.2.

We compared the MINTS method to six models based on existing methods for multiple imputation. As the existing methods assume a linear relationship between variables with missing data, the simulated data was transformed prior to creating multiple imputations using a Box-Cox transformation. For each of the existing methods, $\mathbf{Y}$ was first transformed using the cube root as $\mathbf{Y}^{*}=\mathbf{Y}^{1 / 3}$. Imputations were created on the transformed scale, and the resulting multiply imputed values of $\mathbf{Y}^{*}$ were transformed back to the original scale of $\mathbf{Y}$.

Three of the existing multiple imputation models considered are based on the MICE methodology as implemented in the R package "mice" (van Buuren and GroothuisOudshoorn (2011)). ${ }^{2}$ MICE uses the FCS algorithm, which allows for the specification of separate univariate conditional models for each variable with missing data. The univariate conditional models include all available variables as predictors, for example, the model for $\mathbf{X}$ includes $\mathbf{Y}$, year, and country as predictors. We first considered the default imputation method for continuous data in the mice package, which is predictive mean matching. We refer to this model as MICE PMM. Unlike the other approaches considered, MICE PMM does not explicitly account for the hierarchical structure of the data but is included as a baseline for comparison.

We evaluated two models within the MICE framework that account for the hierarchical structure of the data using the method of Schafer (1997b) and Schafer and Yucel (2002), referred to as the pan method following its implementation in the R package "pan" (Zhao and Schafer (2023)). The function mice.impute.2l.pan within the mice package uses a Gibbs sampler to estimate the conditional linear mixed effects model with homogeneous withingroup variances for each variable with missing data given the other variables. We evaluated a model that includes a country-specific intercept and fixed effects for all covariates in the imputation model. We refer to this model as pan Fixed Effects. For example, imputed values for $X_{c, t} \mid Y_{c, t}$ are modeled with a country-specific intercept, a fixed effect of year, a fixed effect of $Y_{c, t}$, and a homogeneous normally distributed error term. We also considered the pan Random Effects model, which adds random effects of all covariates to the model used in pan Fixed Effects.

We evaluated three models using the Amelia II methodology as implemented in the R package "Amelia" (Honaker and King (2010)). ${ }^{3}$ For complete data $(\mathbf{X}, \mathbf{Y})$, Amelia assumes the joint distribution is multivariate normal. The parameters of the joint distribution are estimated using a combination of bootstrapping and an EM algorithm. Amelia is designed specifically for imputation of hierarchical time series data, which Honaker and King refer to as time series cross-sectional data, through modeling features such as smooth trends over time and allowing for country-specific effects. For our comparisons, we evaluated three implementations of Amelia that were chosen to use the simplest form of the time-series-cross-sectional

[^0]
[^0]:    ${ }^{2}$ mice version 3.14.0 used
    ${ }^{3}$ Amelia version 1.80 used

modeling features in Amelia: a time-series (TS) model, a cross-sectional (CS) model, and a time-series-cross-sectional (TSCS) model. All three of the imputation models are constructed by adding terms to the default multivariate normal joint model for $(\mathbf{X}, \mathbf{Y})$. In the Amelia TS model, a linear effect of time is added. In the Amelia CS model, a country-specific intercept term is added. In the Amelia TSCS model, a country-specific intercept term and a countryspecific linear effect of time are added.

Imputations were created using the default settings in mice and Amelia, with the exception of setting the number of imputations as $M=40$, specifying the form of the imputation models as described above, and specifying bounds of $\mathbf{X} \in[0,100]$ and $\mathbf{Y} \in[0,60]$. Scalar bounds were used for $\mathbf{Y}$ as the mice and Amelia packages do not allow for variable bounds.

We also considered a data augmentation approach that extends the MINTS method to enable estimation of the parameters of the analysis model through the decomposition

$$
p\left(\mathbf{Z}, \mathbf{Y}, \mathbf{X} \mid \boldsymbol{\theta}_{Z}, \boldsymbol{\theta}_{Y}, \boldsymbol{\theta}_{X}\right)=p\left(\mathbf{Z} \mid \mathbf{Y}, \mathbf{X}, \boldsymbol{\theta}_{Z}\right) p\left(\mathbf{Y} \mid \mathbf{X}, \boldsymbol{\theta}_{Y}\right) p\left(\mathbf{X} \mid \boldsymbol{\theta}_{X}\right)
$$

where $\boldsymbol{\theta}_{Z}$ denotes the parameters of the analysis model. The data augmentation approach uses the same models for $\mathbf{Y} \mid \mathbf{X}$ and $\mathbf{X}$ as MINTS, while the model for $\mathbf{Z} \mid \mathbf{Y}, \mathbf{X}$ is given by the analysis model used in the validation exercise. We abbreviate the data augmentation approach based on MINTS as the MINTS DA method. MINTS DA can be used to directly sample from the posterior distributions for the parameters of the analysis model rather than needing to rely on the multiple imputation framework. Medians of the posterior distributions for parameters of interest were used for point estimates, while the 0.025 th and 0.975 th quantiles of the posterior distributions were used for interval estimates. As the estimates of the parameters of interest are not constructed using Rubin's pooling rules, we did not calculate estimates of the Fraction of Missing Information. We note that MINTS DA is considered only for comparison purposes as a method that directly incorporates information about $\mathbf{Z}$ when handling missing data in $\mathbf{Y}$ and $\mathbf{X}$. In practice, the data augmentation approach is not possible to implement in our motivating setting where the substantive analysis of interest and imputation of missing data are conducted independently, and information about $\mathbf{Z}$ and $\mathbf{X}$ are not shared between analyst and imputer.
4.5. Analysis Model Validation Results. For the linear regression analysis model validation, we evaluated how well each multiple imputation method performs for estimation of $Q=\omega_{1}$, the regression coefficient on $\mathbf{Y}$ in the linear regression of $\mathbf{Z}$ on $\mathbf{Y}$. Table 1 summarizes the results of this validation exercise.

Overall, we found MINTS results in the best balance between MAE, coverage, and FMI. Out of the multiple imputation methods considered, MINTS has the smallest MAE in all experiments except MAR $10 \%$ and MAR $40 \%$, where MINTS has the second smallest MAE behind MICE PMM. MINTS has reasonably close to nominal coverage for $95 \%$ intervals at the $10 \%$ and $40 \%$ rates of simulated missingness, but suffers from undercoverage at the $80 \%$ rate. The Amelia TSCS method has closer to nominal coverage than MINTS in the MCAR $80 \%$ and MNAR $80 \%$ experiments at the expense of higher MAE, but MINTS has the closest to nominal coverage in the MAR $80 \%$ experiment.

MINTS has the smallest FMI in eight out of nine experiments. As expected, FMI is much larger for all methods at the $80 \%$ rate, with FMI $>50 \%$ for several methods. This is higher than is typical for the setting of sample survey data that multiple imputation was originally designed for, where FMI is usually $\leq 30 \%$ (Rubin 2007). Given the high FMI, it is thus unsurprising how poorly all multiple imputation methods perform in the experiments at the $80 \%$ rate. In particular, the spline estimation used in MINTS suffers from overfitting at the $80 \%$ rate due to the small number of complete cases available to estimate the splines $f$ and $h$, with some replications having less than 15 complete cases.

None of the existing multiple imputation methods perform consistently well across experiments for estimation of $\omega_{1}$. While MICE PMM can outperform the methods explicitly designed for hierarchical time series data at the lower rates of missingness, the performance of MICE PMM suffers greatly at the highest rate of missingness. The pan and Amelia methods perform similarly to one another at the $10 \%$ rate, but all have larger MAE than MICE PMM. Performance of the pan and Amelia methods generally is best under MCAR, with pan Random Effects and Amelia TSCS performing the best of the group in terms of MAE and coverage.

Multiple imputation using the MINTS method generally has better performance than the data augmentation approach based on MINTS at the lower rates of simulated missingness. However, the data augmentation approach has smaller MAE than all multiple imputation methods at the highest rate of simulated missingness. The multiple imputation methods all have substantial undercoverage in the MAR $80 \%$ and MNAR $80 \%$ experiments, while the data augmentation approach maintains close to nominal coverage. These findings suggest that omission of $\mathbf{Z}$ from the imputation model is likely a major source of bias and undercoverage for the multiple imputation methods when there is a small number of observed values.

TABLE 1
Summary of analysis model validation for nonlinear simulated data for $Q=\omega_{1}$, the regression coefficient on $Y$ in the linear regression of $Z$ on $Y$. MAE denotes mean absolute error, Cvg denotes the average coverage of $95 \%$ intervals as a percentage, and FMI denotes the fraction of missing information as a percentage. MAE is multiplied by 100 before reporting. Results are averaged over the 1000 replications of each experiment. The true value of $Q$ is 2.060 .

![table_0](table_0)

We also conducted a simulation study for data simulated to follow a linear relationship. For the linear simulated data, we considered two uncongenial and two congenial analysis models. Although our primary focus is on the uncongenial setting, the analysis model validation using congenial analysis models and linear simulated data allows us to compare the performance of MINTS with the existing imputation methods in an "ideal" setting for multiple imputation. We found that the existing imputation methods perform better in the analysis model validation for the linear simulated data compared to the nonlinear simulated data. However, for estimation of uncongenial analysis models, we found MINTS still outperforms the existing methods in the linear setting at the $10 \%$ and $40 \%$ rates of simulated missingness. All imputation methods were found to perform well for estimation of congenial analysis models using linear simulated data, with no method consistently standing out from the others across experiments. Details of the simulation study using linear simulated data can be found in Sections 5 and 6 of the Supplementary Material (Liu and Raftery (2025)).
5. Application to Enrollment Data. We further evaluated the performance of MINTS by revisiting the secondary school enrollment data that was described in Section 2. We conducted two validation exercises using the school enrollment data by simulating additional country-years as missing. In the first validation exercise, we evaluated how well MINTS performs for estimation of parameters of interest $Q$ for uncongenial analysis models. This is analogous to the analysis model validation that was conducted for the simulation study.

In the second validation exercise, we evaluated the predictive performance of MINTS for predicting left-out observations of NER. Out-of-sample validation for prediction of individual missing values is less frequently conducted for multiple imputation methods compared to analysis model validation, but has been considered by Gelman, King and Liu (1998); Honaker and King (2010); Nguyen, Carlin and Lee (2017); among others. Although the primary goal of multiple imputation is to create valid estimates of parameters of interest in the presence of missing data rather than recovering the missing values (Rubin (1996)), the prediction of individual missing values can still be of great interest in practice. A multiple imputation method that can perform well for prediction of individual missing values and for creating multiply imputed estimates of quantities of interest is thus of increased utility. We refer to this second validation exercise as "out-of-sample validation."

Finally, we applied the MINTS method to the full school enrollment data set without simulating any additional missing values and created 40 multiple imputations for the countryyears of NER that are missing in the original data set. We also estimated a substantive analysis model of interest using the multiply imputed values of NER created using MINTS and compared these results with the estimates obtained using the other methods considered in the validation exercises.
5.1. Validation Procedure. For both validation exercises using the school enrollment data, we considered eight experiments. Parameters varied in both validation exercises were the rate of simulated missingness $(10 \%, 40 \%, 80 \%)$ and the missing data mechanism (MCAR, MAR, and MNAR), where the same missing data mechanisms used in the simulation study and described in Section 3 of the Supplementary Material (Liu and Raftery (2025)) were also used for the enrollment data. We did not consider the MNAR $80 \%$ experiment for the enrollment data as this resulted in the majority of countries having no observations for NER or GER.

As we simulated additional missing values in a data set that began with missing values, the overall rate of missingness for each experiment is larger than the rate of simulated missingness. For example, the experiments with a $40 \%$ rate of simulated missingness correspond to an overall rate of missingness of $84.8 \%$ for NER. Similarly, the simulated missing data

mechanisms used in the validation exercises describe the missing data mechanism only for observations that are simulated as missing. The true missing data mechanism for the observations that began as missing in the original enrollment data set is unknown.

For the analysis model validation, each experiment was replicated $N_{\text {rep }}=100$ times following an analogous procedure as was described in Section 4.3 for the simulation study. A major difference in the analysis model validation procedure for the enrollment data is the need to distinguish between the country-years that start out as missing and the country-years that are simulated as missing, where only the country-years that are simulated as missing are used for evaluation purposes. To facilitate this distinction, in each replication of each experiment we separated the enrollment data into "started-as-missing", "observed", and "simulated-asmissing" sets. The observed set is the training set for model estimation, while the simulated-as-missing set is the testing set for validation. Imputed values were still created for the started-as-missing set, but we are unable to evaluate the performance of these imputed values as the true values for the started-as-missing set are unknown.

For the out-of-sample validation exercise, we considered one replication of each experiment. We used the same distinction between the country-years that started as missing and the country-years that were simulated as missing, where only the country-years that were simulated as missing are included in the testing set for validation. The out-of-sample validation exercise compares performance metrics for prediction of missing values for NER averaged over all country-years in the testing set.

In both validation exercises, we compared the performance of MINTS with the MICE PMM, pan Fixed Effects, pan Random Effects, Amelia TS, Amelia CS, and Amelia TSCS models that were described in Section 4.4. For the analysis model validation exercise, we additionally compared the multiple imputation methods with the data augmentation approach described in Section 4.4.

# 5.2. Analysis Model Validation. 

5.2.1. Analysis Model. We are interested in estimating the relationship between NER and the Total Fertility Rate (TFR), which is a period measure of the expected number of children a woman would bear in her lifetime if she were to experience the period-specific fertility rates at each age and if she lived through the reproductive age range of 15-49. There is a well-established negative association between education and fertility in the high-fertility setting (Hirschman (1994)). One mechanism through which education is posited to have a negative effect on fertility is through the educational enrollment of children, where increased enrollment increases the cost of raising children (Axinn and Barber (2001)). Children who are enrolled in school have reduced capacity for work and may incur increased costs for caregivers through fees related to tuition, uniforms, and textbooks (Easterlin and Crimmins (1985); Caldwell (1982); Caldwell, Reddy and Caldwell (1985)). To estimate this relationship, we use annual estimates of TFR from the 2022 revision of the United Nations World Population Prospects (United Nations (2022)). We restrict our analyses to the high-fertility context, defined here as the years where a country has TFR $>2.5$ children per woman.

The analysis model is the linear regression of TFR on NER, where the quantity of interest $Q=\beta_{1}$ is the regression coefficient on NER in the regression

$$
\begin{aligned}
\operatorname{TFR}_{c, t} & =\beta_{0}+\beta_{1} \mathrm{NER}_{c, t}+\varepsilon_{c, t}^{\beta} \\
\varepsilon_{c, t}^{\beta} & \sim N\left(0, \sigma_{\varepsilon_{t}}^{2}\right)
\end{aligned}
$$

For each replication of each experiment, the analysis model is estimated using only the country-years that were simulated as missing and where TFR $>2.5$. We also conducted

analysis model validation using a random intercept model for TFR on NER, results of which are available in Section 4 of the Supplementary Material (Liu and Raftery (2025)).

In this validation exercise, the analysis model is uncongenial to all imputation models considered due to the omission of the analysis model outcome variable $\mathbf{Z}=$ TFR from the imputation models. This reflect our motivating setting where analysis of the multiply imputed values occurs independently from multiple imputation, and information about the outcome variable is not known during the imputation task. For comparison purposes, we also consider a data augmentation algorithm based on MINTS to represent the setting where imputation of missing values and estimation of the substantive analysis model can be conducted simultaneously.
5.2.2. Model Implementation. GER is the auxiliary variable $\mathbf{X}$ and NER is the variable of interest $\mathbf{Y}$. To satisfy the assumption of the MINTS method that the auxiliary variable is observed at least once for each country, we excluded all countries that have no observed values for GER. The bounds of the MINTS imputation model were set based on substantive knowledge of the possible ranges of NER and GER: NER is a percentage, GER is a positive rate, and $\mathrm{NER}_{c, f} \leq \mathrm{GER}_{c, f}$. The bounds of the model for $\mathbf{X}$ are set as $X_{\text {lom }}=0$ and $X_{\text {np }}=\infty$, while the bounds of the model for $\mathbf{Y} \mid \mathbf{X}$ were set as $Y_{\text {lom }}=0$ and $Y_{\text {np }}=\min \left(X_{c, f}, 100\right)$. Imputations were created using MINTS for each replication of each experiment by running 10 chains of the MCMC algorithm until convergence was reached in the estimation phase. The total number of iterations differed across experiments, with the experiments with larger rates of simulated missingness requiring a larger number of iterations to achieve convergence. After burn-in, the number of iterations per chain ranged from 5,000 to 35,000 . In the imputation phase, an additional 4,000 iterations was run for each chain and four iterations were selected from each chain to produce a total of $M=40$ completed data sets following the procedure described in Section 3.3.2.

Multiple imputations were created using the models based on the MICE and Amelia methods following the same implementation as described in Section 4.4 with two exceptions. First, the school enrollment data was not transformed prior to using the MICE and Amelia methods, as we were unable to find a transformation that substantially improved linearity for the relationship between $\mathbf{X}$ and $\mathbf{Y}$. Second, the bounds of each model were specified as $\mathbf{X} \in[0, \infty)$ and $\mathbf{Y} \in[0,100]$. The data augmentation method based on MINTS was also implemented as described in Section 4.4.
5.2.3. Results. Table 2 summarizes the results of the analysis model validation for estimation of $Q=\beta_{1}$, the regression coefficient on NER in the linear regression of TFR on NER. MINTS has the smallest MAE out of the multiple imputation methods considered in all but the MAR $80 \%$ experiment. MINTS also has the smallest FMI in all experiments and close to nominal coverage in all but the MNAR $40 \%$ experiment. Out of the previously existing methods, pan Fixed Effects performs the best overall with the smallest MAE in the MAR $80 \%$ experiment and the closest to nominal coverage in the MNAR $40 \%$ experiment. The data augmentation approach based on MINTS has the smallest MAE and closest to nominal coverage in the MNAR experiments, but falls behind several multiple imputation methods in the experiments where the MAR assumption is satisfied.

We also considered a validation exercise using a random intercept analysis model for the regression of TFR on NER. For the $10 \%$ rate of simulated missingness, MINTS has the best performance for estimation of the fixed effect coefficient on NER in the random intercept analysis model. The pan Random Effects model tends to perform the best for estimation of the fixed effect coefficient at higher rates of missingness, while MINTS performs the best for estimation of the variance of the random intercepts. Full details of this analysis model validation exercise can be found in Section 4 of the Supplementary Material (Liu and Raftery (2025)).

TABLE 2
Summary of analysis model validation for enrollment data for $Q=\beta_{1}$, the regression coefficient on NER in the linear regression of TFR on NER. MAE denotes mean absolute error, Cvg denotes the average coverage of $95 \%$ intervals as a percentage, and FMI denotes the fraction of missing information as a percentage. MAE is multiplied by 100 before reporting. Results are averaged over the 100 replications of each experiment. The value of $Q$ estimated using the observed country-years from the full enrollment data set is -0.043 .

![table_1](table_1)

5.3. Out-of-Sample Validation. Next, we evaluated the predictive performance of each method for imputing the individual values of NER that were simulated as missing. In each experiment, the performance of point estimates was evaluated using the mean absolute error, where the mean was taken over all country-years in the testing set. The performance of the predictive intervals was evaluated by checking the average interval widths and coverage of the $95 \%$ intervals with respect to the observations in the testing set, where coverage is calculated as the proportion of the intervals that contained the true left-out values of NER. We also evaluated how well each imputation method balances the trade-off between interval width and coverage for the $95 \%$ intervals using the average negatively-oriented interval score from Gneiting and Raftery (2007). For a $95 \%$ prediction interval, the interval score is defined as

$$
I S=\frac{1}{n} \sum_{x}\left[(u-l)+\frac{2}{0.05} 1\{x<l\}+\frac{2}{0.05} 1\{x>u\}\right]
$$

where $(l, u)$ is the prediction interval, $n$ is the number of observations in the testing set, and the sum is over all true values $x$ for observations in the testing set.

The out-of-sample validation exercise evaluates the posterior predictive distribution of the missing values given the observed values. Samples from the posterior predictive distribution

of the missing values from the MINTS method were obtained using a slight modification of the imputation procedure, details of which can be found in Section 7 of the Supplementary Material (Liu and Raftery (2025)). Details of how samples from the posterior predictive distributions were obtained for the MICE and Amelia methods can also be found in Section 7 of the Supplementary Material (Liu and Raftery (2025)). Medians from the estimated posterior predictive distributions were used as point estimates for the imputed values and the 0.025 and 0.975 quantiles of the estimated posterior predictive distributions were used as $95 \%$ interval estimates.
5.3.1. Results. The results of the out-of-sample validation exercise are summarized in Table 3. MINTS results in the smallest MAE, narrowest interval width, and smallest interval score in all experiments. MINTS has close to nominal coverage in all experiments except for MNAR $40 \%$, where coverage is below nominal. MINTS generally also produces narrower interval widths compared to the existing methods; these intervals appear to be sufficiently wide under MCAR and MAR, but may be too narrow under MNAR.

MICE PMM performs the worst overall, with comparatively large MAE and undercoverage in all experiments. This is perhaps unsurprising, as MICE PMM is the only method that does not account for the hierarchical structure of the data. Amelia TS suffers from similarly large MAE as MICE PMM, but retains close to nominal coverage in experiments under MCAR and MAR thanks to its wider intervals. Out of the previously existing methods, pan Random Effects and Amelia TSCS perform the best overall. Amelia TSCS tends towards undercoverage, having larger MAE and narrower intervals than pan Random Effects in most experiments, while pan Random Effects tends towards overcoverage.

We illustrate the out-of-sample validation results for the MINTS method for selected experiments in Figures 3 and 4. Observations in the training set are shown as solid circles in black for GER and red for NER. Posterior medians for the imputed values of NER are shown as red open circles, while the red shaded regions represent the $95 \%$ posterior predictive intervals. Imputed values are plotted for both the country-years that started as missing in the school enrollment data set and the country-years that were simulated as missing for the testing set. The true values of NER for the country-years in the testing set are shown as solid blue diamonds. Figure 3 shows the out-of-sample validation results for Afghanistan, Belgium, Spain, and Nigeria for the MCAR $40 \%$ experiment. Overall, the posterior predictive distributions for imputed values of NER result in plausible time series trends for each country, with the majority of the observations of NER that were simulated as missing captured within the $95 \%$ intervals. Results for the same example countries are shown in Figure 4 for the MAR $80 \%$ experiment. The predictive intervals are much wider overall for the MAR $80 \%$ experiment compared to the MCAR $40 \%$ experiment. This is especially apparent for Spain, which has many observations of NER and GER in early years and thus had a high proportion of observed values that were simulated as missing. Despite the very large amount of missing data in the experiments using the $80 \%$ rate of simulated missingness, we find the MINTS still imputes plausible country-specific trends that reflect our knowledge of how school enrollment rates change over time.
5.4. Full Enrollment Data Results. We used MINTS to create 40 multiple imputations for the missing country-years in the original school enrollment data set without simulating any additional country-years as missing. The original data set has a large amount of missing data for NER, with about $73.0 \%$ of the 10,302 country-years missing. However, we have partial information about the level of school enrollment arising from GER and the hierarchical time series structure of the data for many of these missing country-years. About $48.8 \%$ of the 7,524 country-years where NER is missing have observed values of GER. In these countryyears, the coarse measure of school enrollment (GER) provides us with partial information

TABLE 3
Summary of out-of-sample validation for enrollment data for the country-years where NER was simulated as missing. MAE denotes mean absolute error, Cvg denotes the average coverage of $95 \%$ intervals as a percentage, Width denotes the average width of $95 \%$ intervals, and IS denotes the interval score for $95 \%$ intervals. Results are averaged over all NER observations simulated as missing in each experiment.

![table_2](table_2)

about the refined measure of school enrollment (NER). Partial information about each country's likely level of enrollment and likely trend over time in enrollment can also be obtained from the hierarchical time series structure of the data. For these reasons, we believe multiple imputation of NER is appropriate despite the large amount of missing data.

The prior distributions for MINTS were specified using the data-based algorithm to determine the value of the control parameters. For the global parameters, the data-based algorithm results in the following prior distributions:

$$
\begin{gathered}
\sigma_{X}^{2} \sim \operatorname{InvGamma}\left(2, \delta_{X}=11.5\right) \\
\mu_{\text {drift }} \sim N\left(\nu_{\text {drift }}=0.994, \zeta_{\text {drift }}^{2}=0.00204\right) \\
\sigma_{\text {drift }}{ }^{2} \sim \operatorname{InvGamma}\left(2, \delta_{\text {drift }}=1.87\right) \\
\sigma_{Y}^{2} \sim \operatorname{InvGamma}\left(2, \delta_{Y}=5.06\right) \\
\mu_{0} \sim N\left(0, \zeta_{0}^{2}=0.00233\right) \\
\sigma_{0}^{2} \sim \operatorname{InvGamma}\left(2, \delta_{0}=2.65\right)
\end{gathered}
$$

The joint prior distribution of $\left(Y_{c, 0}, X_{c, 0}\right)$ was estimated using an early subset of data that covered years 1970 to 1980 to balance between only including observations close to the first time period and having a sufficient number of observations in the chosen subset. The truncation for the joint prior distribution is specified based on substantive knowledge that $\mathbf{X}$

and $\mathbf{Y}$ are generally increasing over time. The joint prior distribution of $\left(Y_{c, 0}, X_{c, 0}\right)$ is

$$
\left[\begin{array}{l}
Y_{c, 0} \\
X_{c, 0}
\end{array}\right] \sim T N\left(\boldsymbol{\mu}_{\text {early }}=\left[\begin{array}{l}
40.4 \\
47.2
\end{array}\right], \boldsymbol{\Sigma}_{\text {early }}=\left[\begin{array}{ll}
607.9 & 649.4 \\
649.4 & 718.0
\end{array}\right]\right)
$$

where the truncation is such that $X_{c, 0}$ is bounded from below by 0 and from above by the maximum observed value of GER for country $c . Y_{c, 0}$ is bounded from below by 0 and from above by the minimum of $X_{c, 0}$ and the maximum observed value of NER for country $c$.

To check that these prior distributions are appropriate for the school enrollment application, we conducted a prior predictive check and visually compared the prior and posterior distributions for the parameters specified using the data-based algorithm. We found that the chosen prior distributions are sufficiently diffuse and do not overwhelm the posterior. Details of these assessments can be found in Section 9 of the Supplementary Material (Liu and Raftery (2025)).

Figure 5 illustrates the multiply imputed values for NER from MINTS for Afghanistan, Belgium, Spain, and Nigeria. The multiple imputations for NER are shown as translucent grey circles, while the observed values of NER and GER from the original data set are shown as open and solid black circles, respectively. Despite the large amount of missing data for NER in the full enrollment data set, we find MINTS produces imputations that result in plausible imputed trends over time for all countries.
![img-2.jpeg](img-2.jpeg)

Fig 3: MCAR $40 \%$ experiment results for selected countries from the out-of-sample validation for enrollment data. Solid black and red circles indicate values in the training set for GER and NER, respectively. Solid blue diamonds indicate the true values in the testing set for NER. Open red circles indicate the median imputed values of NER and the red shaded regions indicate the $95 \%$ posterior quantiles for imputed values of NER, where values are imputed for country-years in the testing set and country-years that started as missing in the enrollment data set.

![img-3.jpeg](img-3.jpeg)

Fig 4: MAR 80\% experiment results for selected countries from the out-of-sample validation for enrollment data. Solid black and red circles indicate values in the training set for GER and NER, respectively. Solid blue diamonds indicate the true values in the testing set for NER. Open red circles indicate the median imputed values of NER and the red shaded regions indicate the $95 \%$ posterior quantiles for imputed values of NER, where values are imputed for country-years in the testing set and country-years that started as missing in the enrollment data set.

A CSV file containing the 40 completed data sets for both NER and GER and a CSV file containing the median imputed values for both NER and GER are provided in the Supplementary Material (Liu and Raftery (2025)). We note that the intended use of MINTS is to create multiple imputations for the variable of interest NER, and the auxiliary variable GER is only imputed out of necessity. However, we make the imputed values of GER available to provide additional context for how the MINTS method works for the school enrollment application.

We also created multiply imputed estimates for the linear regression of TFR on NER, where $M=40$ multiple imputations were created using MINTS and the existing multiple imputation methods considered in the validation exercises. We estimated the same linear regression of TFR on NER that was used in the analysis model validation in Section 5.2.1, where the quantity of interest is the regression coefficient $\beta_{1}$. Table 4 summarizes the multiply imputed estimates of $\beta_{1}$ from MINTS and the six existing multiple imputation methods using the full enrollment data along with estimates from the data augmentation approach.

In the analysis model validation exercise using the school enrollment data, we found that MINTS resulted in the smallest MAE and closest to nominal coverage, and that pan Fixed Effects was the most competitive alternative out of the existing multiple imputation methods. When applied to the full school enrollment data, MINTS and pan Fixed Effects result in similar multiply imputed estimates of $\beta_{1}$. Both methods estimate that an increase in NER from $0 \%$ to $100 \%$ is associated with a reduction in TFR of over 4.2 children per woman,

where MINTS estimates a smaller effect size than pan Fixed Effects. MINTS and pan Fixed Effects also result in confidence intervals of approximately the same width, but pan Fixed Effects has a smaller estimated FMI.

TABLE 4
Comparison of multiply imputed estimates of $Q=\beta_{1}$, the regression coefficient on NER in the linear regression of TFR on NER, created using $M=40$ multiple imputations from MINTS and six existing multiple imputation methods. $\hat{Q}_{40}$ denotes the pooled point estimates, $95 \%$ CI denotes the $95 \%$ confidence intervals for $\hat{Q}_{40}$, and FMI denotes the fraction of missing information as a percentage. $\hat{Q}_{40}$ and the confidence interval bounds are multiplied by 100 before reporting.

![table_3](table_3)

The other five models based on existing methods (MICE PMM, pan Random Effects, Amelia TS, Amelia CS, and Amelia TSCS) had substantial bias and undercoverage in the analysis model validation exercise for estimation of $\beta_{1}$. When applied to the full school enrollment data, these five models all lead to multiply imputed point estimates for $\beta_{1}$ that
![img-4.jpeg](img-4.jpeg)

Fig 5: Results of $M=40$ imputations for NER for selected countries. Open and solid black circles indicate observed values of NER and GER, respectively, from the enrollment data set. Translucent grey circles indicate imputed values of NER, where a total of 40 imputations were created for each missing value.

suggest an increase in NER from $0 \%$ to $100 \%$ is associated with a reduction in TFR of less than 3.6 children per woman. Based on the findings of the analysis model validation exercise, these estimates are likely to be biased compared to the estimates from MINTS and pan Fixed effects and may underestimate the relationship between TFR and NER.

The data augmentation approach based on MINTS results in the largest estimated effect size, with a point estimate for $\beta_{1}$ that suggests an increase in NER from $0 \%$ to $100 \%$ is associated with a reduction in TFR of about 5.4 children per woman. In the analysis model validation exercise for estimation of $\beta_{1}$, we found that the data augmentation approach had larger MAE than MINTS when the MAR assumption was satisfied. However, the data augmentation approach had the smallest MAE and closest to nominal coverage in the MNAR experiments. If we have reason to suspect a strong violation of the MAR assumption for the full school enrollment data set, then the estimates from MINTS and pan Fixed Effects may also underestimate the true relationship between TFR and NER.

An important limitation of the multiple imputation results presented in this section is that the complete cases in the school enrollment data set only comprise $26.8 \%$ of the possible country-years. The MINTS method therefore relies on a relatively small proportion of the data to estimate the relationship between NER and GER. Our validation exercises using the school enrollment data suggest that MINTS produces unbiased multiply imputed estimates with reasonable coverage even in settings with a very high percentage of missing data. However, the small number of complete cases increases the risk that the assumptions of MINTS are violated. The restriction of MINTS to the bivariate setting increases the risk that the ignorability assumption is violated, as the probability of NER being missing for the country-years where both NER and GER are missing may depend on external factors that are not accounted for in the bivariate imputation model. The country-years with both NER and GER missing could also be systematically different from the country-years where at least one measure of school enrollment is observed, and the relationships between NER and GER estimated using the observed country-years may not be appropriate for country-years where both measures of enrollment are missing. If the true missing data mechanism is strongly MNAR, the results from our simulation studies and validation exercises suggest that multiply imputed point estimates from MINTS are likely to be biased and interval estimates are likely to suffer from undercoverage. Incorporation of additional variables that are predictive of the probability of observing NER and GER into the imputation model could improve the plausibility of the MAR assumption, and generalization of the MINTS method to the multivariate setting to accommodate such variables is of interest for future work.
6. Discussion. We developed a multiple imputation method for hierarchical time series data that accommodates nonlinear relationships between variables. We evaluated the performance of the proposed method using a simulation study and an application to a data set on secondary school enrollment rates. Through comparisons with existing methods for multiple imputation of hierarchical time series data, we found that the proposed MINTS method can lead to substantial gains in performance when variables in the imputation model have a nonlinear relationship.

In the simulation study, MINTS generally performed better for estimation of parameters in uncongenial analysis models compared to existing models based on the MICE and Amelia methodologies. We found that MINTS is likely to balance the tradeoff between MAE and coverage better than existing methods when there is a nonlinear relationship between variables, though undercoverage is a concern at very high rates of missingness when the number of complete cases is small. MINTS still performed well in validation exercises with a linear relationship between variables, but we found the difference in performance between MINTS and the existing methods was less pronounced.

TABLE 5
Average mean absolute error (MAE) across all experiments for each multiple imputation method within each validation exercise. For the enrollment data, OOS denotes to the out-of-sample validation and $\beta_{1}$ is the parameter from the linear regression analysis model validation. For the nonlinear simulated data, $\omega_{1}$ is the parameter from the linear regression analysis model validation. MAE for the $\beta_{1}$ and $\omega_{1}$ columns are multiplied by 100 before reporting.

![table_4](table_4)

For the application to the school enrollment data, we evaluated how well MINTS performed for estimation of parameters in uncongenial analysis models and for prediction of individual missing values. MINTS resulted in improved performance for estimation of the linear regression of TFR on NER compared to existing models based on MICE and Amelia, with the smallest or second smallest MAE in all experiments and close to nominal coverage in all but one experiment. MINTS generally had good performance for estimation of the random intercept model regressing TFR on NER, with the smallest MAE for estimation of the variance of the random intercepts across experiments. However, pan Random Effects performed better for estimation of the fixed effect coefficient on NER at higher rates of missingness. For random intercept models, MINTS is likely to be a better choice than existing methods if a components of variance analysis is of interest, but pan Random Effects could be a better choice if only the fixed effect coefficient is of interest. In the out-of-sample validation exercise, we found that MINTS resulted in substantial improvements for prediction of individual missing values of NER compared to existing methods, with smaller MAE, narrower intervals, and smaller interval scores across experiments while maintaining close to nominal coverage in all but one experiment.

To facilitate easier comparisons across validation exercises, we summarize the average MAE across experiments for each multiple imputation model and the data augmentation approach based on MINTS in Table 5. A version of Table 5 that includes all validation exercises conducted is available in Section 8 of the Supplementary Material (Liu and Raftery (2025)). We note that Table 5 should not be interpreted as inferential and is only of interest as an exploratory comparison tool to enable a simple comparison of one metric from the full evaluation results. Out of the multiple imputation methods considered, MINTS consistently results in the smallest average MAE across experiments in each validation exercise. For the validation exercise using the nonlinear simulated data, the data augmentation approach resulted in the smallest average MAE, followed by multiple imputation using MINTS.

We note that all of the multiple imputation methods compared assume that the missing data mechanism is ignorable. We conducted sensitivity analyses to evaluate how robust each imputation model is to one type of violation of the ignorability assumption through the MNAR experiments. In the simulation studies, we found that all imputation methods considered were relatively robust to the violation of ignorability when the rate of simulated missingness was low. However, substantial increases in bias and undercoverage were seen at the $40 \%$ and $80 \%$ rates. MINTS tended to be the most robust to these violations but still suffered from bias and undercoverage, especially at the $80 \%$ rate. No imputation method performed consistently

well in the MNAR experiments for the school enrollment data, though we found MINTS and the pan models tended to be the most robust to violations of ignorability. Across validation exercises, the data augmentation approach based on MINTS generally performed better than all of the multiple imputation methods in the MNAR experiments.

Our results suggest that MINTS is generally able to balance good predictive performance for individual missing values with good performance for multiply-imputed estimates of parameters in substantive analysis models. However, MINTS should be used with caution if a strong violation of the MAR assumption is suspected. Additionally, MINTS is not recommended for use if there is a very small number of observed values available to estimate the imputation model. This small sample size setting occurred for the nonlinear and linear simulated data sets, where some replications of the experiments at the $80 \%$ rate of simulated missingness had fewer than 15 complete cases of $\mathbf{X}$ and $\mathbf{Y}$ after simulating data as missing. Although our validation exercises suggest MINTS tends to perform better than the existing multiple imputation methods in this small sample size setting, MINTS still resulted in larger bias than the data augmentation approach and had below nominal coverage. If analysts have access to $\mathbf{X}, \mathbf{Y}$, and $\mathbf{Z}$, data augmentation could be a better alternative to multiple imputation in settings with a strong violation of the MAR assumption or with a very small number of complete cases. However, the data augmentation approach may not be practical if analysts are interested in more than one analysis using $\mathbf{Y}$. Unlike multiple imputation, the data augmentation approach is specific to a given analysis model and must be run separately for each analysis model of interest.

In this paper, we focused on the setting where the analysis model is uncongenial to the multiple imputation model. This is a common occurrence for social science data, particularly when the imputation phase is conducted independently from the analysis phase. However, if the outcome variable $\mathbf{Z}$ is known during the imputation phase, congeniality between analysis and imputation models is a worthwhile goal. Several methods have been proposed for multiple imputation of hierarchical data under congeniality where the imputation model incorporates features of the substantive analysis model, such as Goldstein, Carpenter and Browne (2014); Enders, Du and Keller (2020); Lüdtke, Robitzsch and West (2020); Grund, Lüdtke and Robitzsch (2021); among others. Many of these methods can account for nonlinear relationships, either through user-specified functional forms (e.g. Erler et al. (2019)) or through automated modeling procedures (e.g. Kim et al. (2014)). Of particular note, Lüdtke, Robitzsch and West (2020) and Grund, Lüdtke and Robitzsch (2021) propose a method called "mdmb" that uses a sequential decomposition of the joint model. The mdmb method ensures congeniality between analysis and imputation models by incorporating a term representing the substantive analysis model into the sequential decomposition following the substantive-model-compatible philosophy of Bartlett et al. (2015). MINTS could be extended to congeniality using the same strategy as mdmb by adding a term representing the substantive analysis model into the decomposition of the joint model as

$$
p\left(\mathbf{Z}, \mathbf{Y}, \mathbf{X} \mid \boldsymbol{\theta}_{Z}, \boldsymbol{\theta}\right)=p\left(\mathbf{Z} \mid \mathbf{Y}, \mathbf{X}, \boldsymbol{\theta}_{Z}\right) p\left(\mathbf{Y} \mid \mathbf{X}, \boldsymbol{\theta}_{Y}\right) p\left(\mathbf{X} \mid \boldsymbol{\theta}_{X}\right)
$$

When $p\left(\mathbf{Z} \mid \mathbf{Y}, \mathbf{X}, \boldsymbol{\theta}_{Z}\right)$ is the exact substantive analysis model of interest, this decomposition corresponds to the data augmentation approach considered in our validation exercises.
7. Conclusion. We have proposed the MINTS method for multiple imputation of hierarchical nonlinear time series data. We considered the bivariate setting where one variable is the variable of interest for analysis that represents a refined measure of an underlying quantity of interest, and the second variable is an auxiliary variable that represents a coarse measure of the same underlying quantity and has a nonlinear relationship with the variable of interest. The refined measure is more difficult to measure and has a greater amount of missing

data than the coarse measure. This setting is motivated by a secondary school enrollment data set that includes two measures of school enrollment rates. The Net Enrollment Rate (NER) is the variable of interest for an analysis of the relationship between the Total Fertility Rate and NER. Measurement of NER can be difficult, as NER incorporates information about both the number and ages of children enrolled in school. The Gross Enrollment Ratio (GER) is a second measure school enrollment that only requires knowledge of the number of children enrolled in school. GER is easier to measure and has a smaller amount of missing data than NER. The MINTS method leverages the strong nonlinear relationship between NER and GER to impute missing values in NER using a combination of smoothing splines, country-specific intercepts, and time series methods.

We compared MINTS with several existing methods for multiple imputation of hierarchical time series data through a simulation study and an application to the school enrollment data. We considered three models within the MICE framework of van Buuren and GroothuisOudshoorn (2011) and three models within the Amelia II framework of Honaker and King (2010). We found that MINTS generally resulted in better performance for estimation of parameters in uncongenial linear regression and random intercept models compared to imputation models based on the MICE and Amelia methodologies in both a simulation study using nonlinear simulated data and an application to the school enrollment data, though undercoverage can be a concern when the sample size is small. We also conducted an out-of-sample validation exercise for prediction of individual missing values using the school enrollment data and found that MINTS resulted in better predictive performance compared to the existing methods. Based on these validation exercises, we believe MINTS has a promising capability to improve the quality of multiply imputed data sets for hierarchical nonlinear time series data.

One limitation of the MINTS method is the use of spline estimation to model the nonlinear relationship between variables in the imputation model. The A-splines method of Goepp, Bouaziz and Nuel (2018) helps to automate the estimation procedure, but as with all spline estimation methodologies there is the risk of overfitting. The MINTS algorithm uses linear splines and modifies the number of starting knots used in the A-spline algorithm when the sample size is small to reduce the risk of overfitting, but the spline estimation settings are likely to require manual tuning for applications of MINTS to other data sets. The risk of overfitting is especially of concern when the number of complete cases is small. The splines $f$ and $h$ estimated using A-splines should be checked for each application to ensure the estimated relationships make sense based on substantive knowledge of the variables in the imputation model. We note that other curve-fitting methods, such as LOESS, could be used instead. The estimation of $f$ and $h$ in MINTS is also limited by the assumption that the nonlinear relationship between $\mathbf{X}$ and $\mathbf{Y}$ does not change substantially across countries and times. If there are a sufficient number of complete cases in the data set, country- or timespecific estimates of $f$ and $h$ could be used instead.

The illustrations of MINTS presented in the simulation studies and the application to the school enrollment data are additionally limited by the use of a data-based algorithm to specify certain hyperparameters in the prior distributions. Although we found that the resulting prior distributions were sufficiently diffuse and did not overwhelm the posterior for these specific applications, a consequence of using the data-based algorithm is that the posterior distributions used to create multiple imputations are approximate rather than fully Bayesian posterior distributions. Alternative methods for specifying these hyperparameters that do not rely on the data, such as expert elicitation or using information from previous studies, could be used to address this limitation.

MINTS also has several practical limitations compared to MICE and Amelia. Currently, MINTS is restricted to the bivariate setting with continuous variables. While we are primarily

motivated by multiple imputation in settings like the school enrollment rates application with two highly related variables that aim to measure the same underlying quantity, incorporation of additional variables into the MINTS model could improve the plausibility of the MAR assumption. In principle, MINTS could be extended to the multivariate setting by adding additional univariate conditional terms to the sequential decomposition of the joint distribution, where careful consideration is needed for the ordering of the added conditional distributions. The imputation models for the added variables could be assumed to be linear or could incorporate a separate spline term for each marginal relationship in the conditional imputation model. MINTS could also be extended to accommodate categorical variables through the use of generalized regression models, for example using similar methodology as Lee and Mitra (2016). Another practical limitation of MINTS is computation time, where the estimation of the MINTS model is much more computationally intense than estimation of the MICE models and the two simpler Amelia models. Computation time could be improved by coding the MCMC algorithm in a more efficient language than R. Extending the MINTS methodology to the multivariate and mixed data type setting and improving the computational efficiency of the MINTS sampling algorithm is of interest for future work.

Acknowledgments. The authors would like to thank the members of the working group on Applied, Bayesian, and Computational Statistics at the University of Washington for their helpful discussion. We also thank the referees, Associate Editor, and Editor for their valuable feedback.

Funding. This work was supported by NICHD grant R01 HD070936.

# SUPPLEMENTARY MATERIAL
## Supplementary Material

PDF containing additional methodological details and validation results

## MINTS_enrollment_results.zip

ZIP file containing a CSV of 40 multiple imputations for secondary school enrollment rates created using the MINTS method, a CSV of the medians of the multiply imputed values, and R code to reproduce the multiple imputations

